<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sean Maguire">
<meta name="dcterms.date" content="2021-05-01">

<title>Sean Maguire - Random forests - in pictures</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sean Maguire</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sm212"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Random forests - in pictures</h1>
            <p class="subtitle lead">An introduction to random forests, with pictures instead of maths / code</p>
                                <div class="quarto-categories">
                <div class="quarto-category">notes</div>
                <div class="quarto-category">stats</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Sean Maguire </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 1, 2021</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-problem" id="toc-the-problem" class="nav-link active" data-scroll-target="#the-problem">The Problem</a></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees">Decision Trees</a></li>
  <li><a href="#random-forests" id="toc-random-forests" class="nav-link" data-scroll-target="#random-forests">Random Forests</a></li>
  <li><a href="#improving-the-forest" id="toc-improving-the-forest" class="nav-link" data-scroll-target="#improving-the-forest">Improving The Forest</a></li>
  <li><a href="#wrap-up" id="toc-wrap-up" class="nav-link" data-scroll-target="#wrap-up">Wrap Up</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<p>Random forests are great. They’re easy to train, they don’t care about outliers, and they have very few assumptions. You can use random forests for almost any problem you come across and, chances are, you’ll end up with a fairly decent predictive model.</p>
<p>But what do random forests actually do? You might have heard something about random forests being “an average of decision trees”, but what does that mean? This post will explain random forests. We’ll start off with decision trees and gradually work our way up to random forests. And - best of all - we’ll do it all with pictures! No maths, no code, just pretty pictures.</p>
<section id="the-problem" class="level1">
<h1>The Problem</h1>
<p>Look at this picture:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dots.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>It’s a bunch of different coloured points. For the rest of this post, we’re going to try to <strong>predict the colour of a point, given its location</strong>.</p>
<p>This sounds like a daft made up problem, but it’s not too different to the sort of problems you’ll see in the ‘real world’. You have two dependent variables (the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> coordinates of a point), and you want to predict a continuous variable (colour). It’s a regression problem.</p>
<p>There’s a fair bit of structure to this data:</p>
<ul>
<li>there are 4 bright horizontal &amp; vertical lines, and they sort of look like a hashtag</li>
<li>there are 4 bright spots where the bright lines overlap</li>
</ul>
<p>A good model should be able to capture this structure.</p>
<p>Instead of just jumping straight to random forests, we’re going to start with a slightly simpler model - <em>decision trees</em>.</p>
</section>
<section id="decision-trees" class="level1">
<h1>Decision Trees</h1>
<p>A decision tree is a sequence of yes/no questions. Each of these yes/no questions ‘split’ the dataset into smaller and smaller chunks. The idea behind decision trees is that, by splitting the data down into small groups, each group will contain data points which are fairly similar to each other. Since the points in each group are fairly similar to each other, the average value in each group will be fairly close to the actual value of each point. This is how predictions are made using decision trees - figure out which group a new data point is in, then predict the average value for that group.</p>
<p>Here’s how our data looks to a simple decision tree:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="depth_1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Clearly, this isn’t the best model in the world. It hasn’t picked up any of the patterns in the data and only ever predicts two values - the model thinks any point on the far left is purple, and all other points are yellow. This is because we’ve fit a very <em>shallow</em> decision tree. The tree is only allowed to make one split, so the best it’ll ever be able to do is split the data into two smaller chunks. If we let the tree make more splits it’ll be able to make smaller chunks of the data, so it should be able to pick up more of the underlying patterns in the data.</p>
<p>Here’s how our data looks to a tree of depth 3:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="depth_3.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>This is slightly better. It’s picked up the bright band on the right hand side, and it’s figured out that the bottom right corner is a darker colour than the other areas. There’s still a lot of patterns which the model hasn’t picked up however.</p>
<p>Here’s how the data looks to a tree of depth 5:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="depth_5.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Now we’re getting somewhere! The model has picked up the two bright vertical bands, has figured out that there is a very bright spot on the left, and has noticed that points in the corners are darker than the rest of the points.</p>
<p>Increasing the tree depth increases the number of splits. This means the tree is able to split the dataset into smaller regions. This increased <em>flexability</em> lets the model find more complex patterns in the data.</p>
<p>You might be temped to keep on increasing the depth of the tree, since it looks like deeper trees make better predictions. This is true, but you need to be careful that you don’t start <em>overfitting</em> your data. Imagine if you made an incredibly deep tree, so deep that each data point was in it’s own group. The predictions from the tree would be absolutely perfect since each point is in it’s own group, and so the average value for the group - the predicition - will be exactly the same as the actual value of the point. But this model hasn’t actually found any patterns in the data, it’s just memorised the value for each datapoint! The goal of machine learning is to figure out patterns in data, then use those patterns to make predictions about new data.</p>
<p>One particularly nice feature about decision trees is what questions they ask when splitting data. The questions are always things like <em>‘is x less than 50?’</em> or <em>‘is z bigger than 264?’</em>. This is really nice because it means that <em>decision trees don’t care about outliers</em>. They don’t care about the actual value of a datapoint, only if that value is above/below some threshold value.</p>
</section>
<section id="random-forests" class="level1">
<h1>Random Forests</h1>
<p>There’s only one downside to decision trees - the predictions they make aren’t amazing. The predictions are quite accurate, but not as accurate as some of the other fancy machine learning models out there. Fortunately there’s a trick we can do to get much more accurate predictions out of decision trees - <strong>ensembling</strong>.</p>
<p>The idea behind ensembling is really simple. Imagine you have loads of different models. You can make predictions with each of these models, giving you a bunch of predictions. Each of these predictions will have an <em>error</em> associated with them. If these errors are</p>
<ul>
<li><em>independent</em> - that is, if knowing something about the error of one prediction doesn’t tell you anything about the error of another prediction, and</li>
<li><em>random</em> - that is, the errors of each model predictions aren’t systematically large/small for particular groups of data</li>
</ul>
<p>Then averaging the predictions will give you a <em>more accurate prediction</em>.</p>
<p>So we need a bunch of models, which are all independent from each other. Can we do something to our data to end up with loads of independent decision trees? If we can, then we can just average the predictions from each of these trees and get a much better model.</p>
<p>Remember what decision trees do - they split the dataset into smaller regions, then make predictions based on which region a point falls into. The splits depend on the underlying patterns in the dataset. If the dataset changes, then the small regions will also change. If we were to take a <em>random sample</em> of the data, we would get a <em>different</em> decision tree.</p>
<p>Let’s give that a go. Here’s two decision trees, each fit to a different random sample of the data:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="both.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>They look like very different models, so we can ensemble them. Here’s the average of the predictions from the two models:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="combo.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>That looks very similar to the original data! It’s picked up the bright lines &amp; bright spots, so it’s managed to find the structure in the data.</p>
<p>This average model is a <strong>random forest</strong>. Here’s the steps for building a random forest:</p>
<ol type="1">
<li>Get some data</li>
<li>Take <em>random</em> samples of the data</li>
<li>Build a decision tree on each of the random samples</li>
<li>Make predictions with each of the decision trees</li>
<li>Average the predictions</li>
</ol>
</section>
<section id="improving-the-forest" class="level1 page-columns page-full">
<h1>Improving The Forest</h1>
<p>Now that we’ve built a random forest, can we make it better? Broadly, there are three ways of improving the performance of an ensemble model:</p>
<ul>
<li>Increase the number of models in the ensemble. More models gives you more opportunities to spot patterns in the data</li>
<li>Improve the performance of the underlying model. For us, that’d mean improving the decision trees (by increasing the depth for example)</li>
<li>Make the models more uncorrelated with each other. If the models are more uncorrelated with each other, then they’re going to be more independent, so the ensemble should be more accurate</li>
</ul>
<p>Random forests do all sorts of tricks to make the models more uncorrelated with each other. The best trick (and one you need to know about) is that the forest <em>isn’t allowed to split on the same variables at each split</em>. Every time the model needs to make a split, it randomly chooses a handful of features to split on. This reduces the chances of several trees splitting on the same feature at the same point, which makes the trees less similar to each other.</p>
<p>All random forest algorithms let you decide how many features you want to consider at each split. There’s a couple of default values which are good to try out if you’re not sure - for classification problems, it’s best to try using <span class="math inline">\(\sqrt{n_{features}}\)</span>. For regression, try out <span class="math inline">\(n_{features}\)</span>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>These are just rough rule-of-thumb defaults. A better idea would be to try grid search, and an even better idea would be to ask a subject matter expert!</p>
</div></div><p>There’s only two features in our dataset (the x &amp; y coordinates), so it doesn’t look like there’s much we can do to make the trees more uncorrelated with each other. Let’s try out the other two bulletpoints.</p>
<p>Here’s a random forest model with <em>1000 trees</em>. Each tree has <em>depth 15</em>, so can split the dataset up into lots of little rectangular regions:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="final.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Looks good! This has found the bright lines &amp; spots (same as before), but now it’s figured out that the spots are all the same colour. Also, the spots look like actual spots. They’re round! It’s pretty amazing that round regions have appeared, considering that the decision trees in the ensemble can only ever make rectangular regions. Given enough flexibility (tree depth), random forests are able to fit <em>arbitrarily complex</em> patterns in data.</p>
</section>
<section id="wrap-up" class="level1">
<h1>Wrap Up</h1>
<p>In this post we’ve seen:</p>
<ul>
<li>Decision trees split datasets up into lots of little rectanglular regions</li>
<li>Decision trees make predictions by figuring out which rectangular region a new data point is in, then predicting the average value of that region</li>
<li>Averaging predictions will give you a better prediction, provided that the predictions are independent from each other and have random errors. This is called ensembling</li>
<li>You can easily make lots of uncorrelated models by training decision trees on different samples of data</li>
<li>Averaging these decision trees makes a random forest</li>
<li>Ensembles can be improved by increasing the number of models in the ensemble, increasing the performance of the models in the ensemble, or by making the models less correlated with each other</li>
</ul>
<p>That’s a lot of stuff! If you want to learn more about random forests, have a read over the <a href="https://www.stat.berkeley.edu/users/breiman/randomforest2001.pdf">original paper</a> which introduced the idea. If you like the idea of ensembles, have a look at this RSS talk <a href="https://www.youtube.com/watch?v=9v6cMnFNiOI">bag of little bootstraps</a> by Michael Jordan. If you want to see another random forest algorithm which introduces even more randomness into the decision trees, check out <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html">extremly randomised trees</a>.</p>
<p>Finally, if you’re interested in the code used to make these models &amp; graphs, my workings are in <a href="https://github.com/sm212/sm212.github.io/blob/master/notebooks/random_forest.ipynb">this notebook</a>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>